{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation du modele avec Keras = Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "\n",
    "my_VGG16 = Sequential()  # Création d'un réseau de neurones vide "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Charger VGG-16 pré-entraîné sur ImageNet et sans les couches fully-connected\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(1000, 1000, 5))\n",
    "\n",
    "# Récupérer la sortie de ce réseau\n",
    "x = model.output\n",
    "\n",
    "# Ajouter la nouvelle couche fully-connected pour la classification à 2 classes\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Définir le nouveau modèle\n",
    "new_model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "#fine-tuning total\n",
    "for layer in model.layers:\n",
    "   layer.trainable = True\n",
    "\n",
    "# Compiler le modèle \n",
    "new_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraîner sur les données d'entraînement (X_train, y_train)\n",
    "model_info = new_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de la première couche de convolution, suivie d'une couche ReLU\n",
    "my_VGG16.add(Conv2D(64, (3, 3), input_shape=(224, 224, 3), padding='same', activation='relu'))\n",
    "# Ajout de la deuxième couche de convolution, suivie  d'une couche ReLU\n",
    "my_VGG16.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Ajout de la première couche de pooling\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "# Ajout du deuxième bloc de convolution, suivie d'une couche ReLU\n",
    "my_VGG16.add(Conv2D(128, (3, 3), input_shape=(112, 112, 64), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "# Ajout de la deuxième couche de pooling\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "# Ajout du troisième bloc de convolution, suivie d'une couche ReLU\n",
    "my_VGG16.add(Conv2D(256, (3, 3), input_shape=(56, 56, 128), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "# Ajout de la troisième couche de pooling\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "# Ajout de la quatrième couche de convolution, suivie d'une couche ReLU\n",
    "my_VGG16.add(Conv2D(512, (3, 3), input_shape=(28, 28, 256), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "# Ajout de la cinquième couche de pooling\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "# Ajout de la cinquième couche de convolution, suivie d'une couche ReLU\n",
    "my_VGG16.add(Conv2D(512, (3, 3), input_shape=(14, 14, 512), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "# Ajout de la cinquième couche de pooling\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "my_VGG16.add(Flatten())  # Conversion des matrices 3D en vecteur 1D\n",
    "# Ajout de la première couche fully-connected, suivie d'une couche ReLU\n",
    "my_VGG16.add(Dense(4096, activation='relu'))\n",
    "# Ajout de la deuxième couche fully-connected, suivie d'une couche ReLU\n",
    "my_VGG16.add(Dense(4096, activation='relu'))\n",
    "# Ajout de la dernière couche fully-connected qui permet de classifier\n",
    "my_VGG16.add(Dense(1000, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 145s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Utilisation du VGG-16 pré-entraîné\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16() # Création du modèle VGG-16 implementé par Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input , decode_predictions\n",
    "\n",
    "img = load_img('cat.jpg', target_size=(224, 224))  # Charger l'image\n",
    "img = img_to_array(img)  # Convertir en tableau numpy\n",
    "img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))  # Créer la collection d'images (un seul échantillon)\n",
    "img = preprocess_input(img)  # Prétraiter l'image comme le veut VGG-16\n",
    "\n",
    "y = model.predict(img)  # Prédir la classe de l'image (parmi les 1000 classes d'ImageNet)\n",
    "\n",
    "\n",
    "# Afficher les 3 classes les plus probables\n",
    "print('Top 3 :', decode_predictions(y, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
