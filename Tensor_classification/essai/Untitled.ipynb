{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "import imutils\n",
    "import shutil\n",
    "import os\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter \n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.compat.v1 as tf\n",
    "#from tensorflow.keras.models import model_from_json\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#from object_detection.utils import label_map_util\n",
    "#from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "tf.gfile = tf.io.gfile\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 2606, done.\u001b[K\n",
      "remote: Counting objects: 100% (2606/2606), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2288/2288), done.\u001b[K\n",
      "remote: Total 2606 (delta 509), reused 1321 (delta 283), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (2606/2606), 31.40 MiB | 7.84 MiB/s, done.\n",
      "Resolving deltas: 100% (509/509), done.\n"
     ]
    }
   ],
   "source": [
    "#Protobuf 3.0.0\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "    while \"models\" in pathlib.Path.cwd().parts:\n",
    "        os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "    !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/souhila/Diatoms/Tensor_classification/models/research\n",
      "Requirement already satisfied: Pillow>=1.0 in /mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages (from object-detection==0.1) (7.1.1)\n",
      "Requirement already satisfied: Matplotlib>=2.1 in /mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages (from object-detection==0.1) (3.2.1)\n",
      "Requirement already satisfied: Cython>=0.28.1 in /mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages (from object-detection==0.1) (0.29.17)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages (from Matplotlib>=2.1->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.11 in /mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages (from Matplotlib>=2.1->object-detection==0.1) (1.18.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages (from Matplotlib>=2.1->object-detection==0.1) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages (from Matplotlib>=2.1->object-detection==0.1) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages (from Matplotlib>=2.1->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: six in /mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages (from cycler>=0.10->Matplotlib>=2.1->object-detection==0.1) (1.14.0)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py): started\n",
      "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
      "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1082205 sha256=987d77f36cb0f66efd2960cf2d8b5301188f1e5808cfa5053a826e64a37063c5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qwbkj0za/wheels/7e/de/ad/73f3109c9231a7812d216030f70b889e41befafaa5baf001de\n",
      "Successfully built object-detection\n",
      "Installing collected packages: object-detection\n",
      "Successfully installed object-detection-0.1\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd models/research\n",
    "pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Import the object detection module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch tf1 into `utils.ops`\n",
    "utils_ops.tf = tf.compat.v1\n",
    "\n",
    "# Patch the location of gfile\n",
    "tf.gfile = tf.io.gfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Model pr√©paration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_model(model_name):\n",
    "    base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "    model_file = model_name + '.tar.gz'\n",
    "    model_dir = tf.keras.utils.get_file(\n",
    "        fname=model_name, \n",
    "        origin=base_url + model_file,\n",
    "        untar=True)\n",
    "\n",
    "    model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "\n",
    "    model = tf.saved_model.load(str(model_dir))\n",
    "    model = model.signatures['serving_default']\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('models/research/object_detection/test_images/image1.jpg'),\n",
       " PosixPath('models/research/object_detection/test_images/image2.jpg')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
    "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images')\n",
    "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
    "TEST_IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-365b9f284648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ssd_mobilenet_v1_coco_2017_11_17'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdetection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmasking_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-903f441fae65>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"saved_model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'serving_default'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m   \"\"\"\n\u001b[0;32m--> 528\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[1;32m    557\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m       \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_v1_in_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load_v1_in_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags)\u001b[0m\n\u001b[1;32m    252\u001b[0m   \u001b[0;34m\"\"\"Load a v1-style SavedModel as an object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m   \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EagerSavedModelLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load_v1_in_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, tags)\u001b[0m\n\u001b[1;32m    202\u001b[0m     wrapped = wrap_function.wrap_function(\n\u001b[1;32m    203\u001b[0m         \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_graph_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         signature=[])\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph_returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages/tensorflow_core/python/eager/wrap_function.py\u001b[0m in \u001b[0;36mwrap_function\u001b[0;34m(fn, signature, name)\u001b[0m\n\u001b[1;32m    609\u001b[0m           collections={}),\n\u001b[1;32m    610\u001b[0m       \u001b[0mvariable_holder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       signature=signature)\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages/tensorflow_core/python/eager/wrap_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn_graph, variable_holder, attrs, signature)\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_function_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     super(WrappedFunction, self).__init__(\n\u001b[0;32m--> 229\u001b[0;31m         fn_graph, attrs=attrs, signature=signature)\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_signature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func_graph, attrs, signature, shared_func_graph)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;31m# FuncGraph directly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m     self._delayed_rewrite_functions = _DelayedRewriteGradientFunctions(\n\u001b[0;32m-> 1511\u001b[0;31m         func_graph, self._attrs, self._garbage_collector)\n\u001b[0m\u001b[1;32m   1512\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_order_tape_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_higher_order_tape_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func_graph, attrs, func_graph_deleter)\u001b[0m\n\u001b[1;32m    599\u001b[0m     self._inference_function = _EagerDefinedFunction(\n\u001b[1;32m    600\u001b[0m         \u001b[0m_inference_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         self._func_graph.inputs, self._func_graph.outputs, attrs)\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, graph, inputs, outputs, attrs)\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EagerDefinedFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages/tensorflow_core/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m   \u001b[0;34m\"\"\"Initialize the context.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m   \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/venv/tf2.1/lib/python3.6/site-packages/tensorflow_core/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m           pywrap_tensorflow.TFE_ContextOptionsSetLazyRemoteInputsCopy(\n\u001b[1;32m    508\u001b[0m               opts, True)\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mcontext_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable"
     ]
    }
   ],
   "source": [
    "model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "detection_model = load_model(model_name)\n",
    "model_name = \"mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\"\n",
    "masking_model = load_model(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detection_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-83a34913629d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetection_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'detection_model' is not defined"
     ]
    }
   ],
   "source": [
    "print(detection_model.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model.output_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "    image = np.asarray(image)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "    # Run inference\n",
    "    output_dict = model(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key:value[0, :num_detections].numpy() \n",
    "                   for key,value in output_dict.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "\n",
    "    # Handle models with masks:\n",
    "    if 'detection_masks' in output_dict:\n",
    "        # Reframe the the bbox mask to the image size.\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "            image.shape[0], image.shape[1])      \n",
    "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                           tf.uint8)\n",
    "        output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def show_inference(model, image_path):\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = np.array(Image.open(image_path))\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(model, image_np)\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        output_dict['detection_boxes'],\n",
    "        output_dict['detection_classes'],\n",
    "        output_dict['detection_scores'],\n",
    "        category_index,\n",
    "        instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "\n",
    "    display(Image.fromarray(image_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    show_inference(detection_model, image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Instance Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\"\n",
    "masking_model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'masking_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-31bf89ff98cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmasking_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'masking_model' is not defined"
     ]
    }
   ],
   "source": [
    "masking_model.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_inference' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c7babe6ddbd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTEST_IMAGE_PATHS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mshow_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasking_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show_inference' is not defined"
     ]
    }
   ],
   "source": [
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    show_inference(masking_model, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'TensorFlow-Tutorials' already exists and is not an empty directory.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/TensorFlow-Tutorials/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-163f70896d89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mwork_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'git clone https://github.com/Hvass-Labs/TensorFlow-Tutorials'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/TensorFlow-Tutorials/'"
     ]
    }
   ],
   "source": [
    "#from mnist import MNIST\n",
    "#data = MNIST(data_dir=\"data/MNIST/\")\n",
    "work_dir = \"/content/TensorFlow-Tutorials/\"\n",
    "if os.getcwd() != work_dir:\n",
    "    !git clone https://github.com/Hvass-Labs/TensorFlow-Tutorials\n",
    "os.chdir(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-936944c0a454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training-set:\\t\\t{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test-set:\\t\\t{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation-set:\\t{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"Validation-set:\\t{}\".format(len(data.validation.labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.31</td>\n",
       "      <td>34.19</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.4936</td>\n",
       "      <td>66900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.47</td>\n",
       "      <td>34.40</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8200</td>\n",
       "      <td>80100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.56</td>\n",
       "      <td>33.69</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.6509</td>\n",
       "      <td>85700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.64</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.1917</td>\n",
       "      <td>73400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.57</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9250</td>\n",
       "      <td>65500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
       "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
       "2    -114.56     33.69                17.0        720.0           174.0   \n",
       "3    -114.57     33.64                14.0       1501.0           337.0   \n",
       "4    -114.57     33.57                20.0       1454.0           326.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0      1015.0       472.0         1.4936             66900.0  \n",
       "1      1129.0       463.0         1.8200             80100.0  \n",
       "2       333.0       117.0         1.6509             85700.0  \n",
       "3       515.0       226.0         3.1917             73400.0  \n",
       "4       624.0       262.0         1.9250             65500.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f12ba995860>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "california_housing_dataframe.hist('housing_median_age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_names = pd.Series(['San Francisco', 'San Jose', 'Sacramento'])\n",
    "population = pd.Series([852469, 1015785, 485199])\n",
    "\n",
    "cities = pd.DataFrame({ 'City name': city_names, 'Population': population })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City name</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>485199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>852469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>1015785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City name  Population\n",
       "2     Sacramento      485199\n",
       "0  San Francisco      852469\n",
       "1       San Jose     1015785"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities.reindex([2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City name</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>1015785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>852469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>485199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City name  Population\n",
       "1       San Jose     1015785\n",
       "0  San Francisco      852469\n",
       "2     Sacramento      485199"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities.reindex(np.random.permutation(cities.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
